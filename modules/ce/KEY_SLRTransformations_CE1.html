---
layout: page
title: "Exercise Key"
subtitle: "SLR Transformations"
author: Derek H. Ogle
css: "/css/modules.css"
---


<hr />
<div class="alert alert-warning">
<strong>Note:</strong>
<ul>
<li>
Don’t include the “mean” in the axis labels if the observed data are shown unless the observed data are means. In these examples the observed data are the frequency of the rattle for an INDIVIDUAL snake and the cumulative number of COVID cases for an INDIVIDUAL day. Thus, “mean” is not part of the variable and thus should not be in the axis labels. In the reading, the MEAN weight loss for a species of petrels was recorded so “mean” was part of the variable and is why it was included in the axis labels. If just the best-fit-line had been shown, without the observed points, then they y-axis would use “mean” because the lines represents a mean.
</li>
<li>
When interpreting the slope on the transformed scale you say as “X” not “mean of X” increases by one and you say “mean of log of Y” not “log of mean of Y” (i.e., logging happened first, then the mean (i.e., best-fit line) was found).
</li>
<li>
For the predictions using a confidence interval, make sure you say “mean” (you are predicting a mean value, not a value, for all individuals). However, for the predictions using a prediction interval, make sure you don’t say “mean” (you are predicting a value for a individual, not a mean for that individual).
</ol>
</ul>
</div>
<hr />
<div id="rattlesnake-rattling" class="section level1">
<h1>Rattlesnake Rattling</h1>
<ol>
<li>When transformed to the log-log scale, the form of the relationship appears to be linear and largely homoscedastic as there is no clear curve or funneling evident in the residual plot (shown below). The residuals do appear to be normal (Anderson-Darling p=0.7765) and there are not apparent outliers (p=0.0844).</li>
<li>There is a significant relationship between log peak frequency and log weight of the rattlesnakes (ANOVA p&lt;0.00005). The scatterplot with the best-fit line superimposed is shown below.</li>
<li>The log peak frequency decreases between 0.099 and 0.188 for each unit increase in log weight of the rattlesnakes.</li>
<li>The peak frequency is multiplied by a value between 0.829 and 0.906 for each 2.718 unit increase in weight of the rattlesnakes. In other words, the peak frequency decreases between 17.1 and 9.4% for each 2.718 unit increase in weight of the rattlesnakes.</li>
<li>The peak frequency for a 454 g rattlesnake is between 4.978 and 7.760 kHz.</li>
<li>The mean peak frequency for all 454 g rattlesnakes is between 5.895 and 6.553 kHz.</li>
</ol>
<div id="r-code-and-results." class="section level3">
<h3>R Code and Results.</h3>
<pre class="r"><code>rs &lt;- read.csv(&quot;https://raw.githubusercontent.com/droglenc/NCData/master/Rattlesnakes.csv&quot;)
lm.rs &lt;- lm(freq~weight,data=rs)
assumptionCheck(lm.rs,lambday=0,lambdax=0)</code></pre>
<p><img src="KEY_SLRTransformations_CE1_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>rs$logfreq &lt;- log(rs$freq)
rs$logweight &lt;- log(rs$weight)
lm.rst &lt;- lm(logfreq~logweight,data=rs)
anova(lm.rst)</code></pre>
<pre><code>Analysis of Variance Table

Response: logfreq
          Df  Sum Sq Mean Sq F value    Pr(&gt;F)
logweight  1 0.48058 0.48058  45.628 2.494e-06
Residuals 18 0.18959 0.01053                  </code></pre>
<pre class="r"><code>ggplot(data=rs,mapping=aes(x=logweight,y=logfreq)) +  
  geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) +  
  labs(x=&quot;log Weight&quot;,y=&quot;log Peak Frequency&quot;) +  
  theme_NCStats() +  
  geom_smooth(method=&quot;lm&quot;)</code></pre>
<pre><code>`geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="KEY_SLRTransformations_CE1_files/figure-html/unnamed-chunk-5-1.png" width="336" /></p>
<pre class="r"><code>( cfs.rst &lt;- cbind(Est=coef(lm.rst),confint(lm.rst)) )  ## log-log scale</code></pre>
<pre><code>                   Est      2.5 %      97.5 %
(Intercept)  2.7039338  2.4483788  2.95948871
logweight   -0.1433303 -0.1879095 -0.09875109</code></pre>
<pre class="r"><code>exp(cfs.rst) ## back-transformed to original scale</code></pre>
<pre><code>                   Est      2.5 %     97.5 %
(Intercept) 14.9383805 11.5695754 19.2881074
logweight    0.8664678  0.8286897  0.9059682</code></pre>
<pre class="r"><code>nd &lt;- data.frame(logweight=log(454))
( plog454 &lt;- predict(lm.rst,newdata=nd,interval=&quot;prediction&quot;) )  # log scale</code></pre>
<pre><code>       fit      lwr      upr
1 1.827025 1.605015 2.049035</code></pre>
<pre class="r"><code>exp(plog454) ## back-transformed to original scale</code></pre>
<pre><code>      fit      lwr      upr
1 6.21537 4.977936 7.760409</code></pre>
<pre class="r"><code>( clog454 &lt;- predict(lm.rst,newdata=nd,interval=&quot;confidence&quot;) )  # log scale</code></pre>
<pre><code>       fit      lwr      upr
1 1.827025 1.774123 1.879927</code></pre>
<pre class="r"><code>exp(clog454) ## back-transformed to original scale</code></pre>
<pre><code>      fit      lwr      upr
1 6.21537 5.895112 6.553026</code></pre>
<p> </p>
</div>
</div>
<div id="initial-covid-19-cases" class="section level1">
<h1>Initial COVID-19 Cases</h1>
<ol>
<li>Assuming exponential growth implies that only the response variable, cumulative cases, should be transformed to the log scale. This was shown in the reading.</li>
<li>This assumption removes the primary curve in the raw data (see residual plot below) but the data seems to have a bit of a cycle as shown in the scatterplot with best-fit line below. The log cumulative cases are below the best-fit line for about the first nine and last six days and generall above the line for the other days. However, there also seems to be a cycle about every 7 days or so … possibly due to reporting on weekends. Homoscedasticity, normality (Anderson-Darling p=0.1943), and no outlier (p&gt;1) all appear to be largely met.</li>
<li>There is a significant relationship between log cumulative cases and days since the 10th confirmed case (ANOVA p&lt;0.00005). The scatterplot with the best-fit line superimposed is also shown below.</li>
<li>The log cumulative cases increases between 0.242 and 0.262 each day.</li>
<li>The cumulative cases increases by a multiple between 1.274 and 1.300 each day. In other words, the cumulative cases increases by between 27.4 and 30.0% each day.</li>
<li>The cumulative cases are predicted to be between 970 and 2612 on day 20.</li>
<li>The cumulative cases are predicted to be between 141897 and 428853 on day 40. One would have to assume continued exponential growth out to at least day 40 for this prediction to be meaningful.</li>
</ol>
<div id="r-code-and-results.-1" class="section level3">
<h3>R Code and Results.</h3>
<pre class="r"><code>cv &lt;- read.csv(&quot;https://derekogle.com/NCMTH207/modules/ce/data/CovidUK.csv&quot;)
lm.cv &lt;- lm(Cum_Cases~Days_Since_10,data=cv)
assumptionCheck(lm.cv,lambday=0)</code></pre>
<p><img src="KEY_SLRTransformations_CE1_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>cv$logCum_Cases &lt;- log(cv$Cum_Cases)</code></pre>
<pre class="r"><code>ggplot(data=cv,mapping=aes(x=Days_Since_10,y=logCum_Cases)) +
  geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) +  
  labs(x=&quot;Days Since 10th Case Confirmed&quot;,y=&quot;log Cumulative Cases&quot;) +  
  theme_NCStats() +  
  geom_smooth(method=&quot;lm&quot;)</code></pre>
<pre><code>`geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="KEY_SLRTransformations_CE1_files/figure-html/unnamed-chunk-8-1.png" width="336" /></p>
<pre class="r"><code>( cfs.cvt &lt;- cbind(Est=coef(lm.rst),confint(lm.rst)) )  ## log-log scale</code></pre>
<pre><code>                   Est      2.5 %      97.5 %
(Intercept)  2.7039338  2.4483788  2.95948871
logweight   -0.1433303 -0.1879095 -0.09875109</code></pre>
<pre class="r"><code>exp(cfs.cvt) ## back-transformed to original scale</code></pre>
<pre><code>                   Est      2.5 %     97.5 %
(Intercept) 14.9383805 11.5695754 19.2881074
logweight    0.8664678  0.8286897  0.9059682</code></pre>
<pre class="r"><code>nd &lt;- data.frame(Days_Since_10=c(20,40))
( plogCC &lt;- predict(lm.cvt,newdata=nd,interval=&quot;prediction&quot;) )  # log scale</code></pre>
<pre><code>        fit       lwr       upr
1  7.372669  6.877567  7.867771
2 12.415864 11.862859 12.968869</code></pre>
<pre class="r"><code>exp(plogCC) ## back-transformed to original scale</code></pre>
<pre><code>         fit         lwr        upr
1   1591.877    970.2629   2611.738
2 246684.104 141897.2962 428852.762</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
