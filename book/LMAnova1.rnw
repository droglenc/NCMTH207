<<echo=FALSE, cache=FALSE, results='hide'>>=
set_parent('Biometry.Rnw')
@

\chapter{One-Way ANOVA}  \label{chap:LMANOVA1}
  \vspace{-21pt}
    \begin{ChapObj}{\boxwidth}
      \textbf{Module Objectives:}
        \begin{Enumerate}
          \item Understand the hypotheses tested with a one-way ANOVA.
          \item Understand the models tested with a one-way ANOVA.
          \item Identify the four assumptions of a one-way ANOVA.
          \item Identify how to test the assumptions of a one-way ANOVA.
          \item Understand why 2-sample t-tests cannot be used to make all pairwise comparisons.
          \item Understand why multiple comparisons follow a significant one-way ANOVA.
          \item Understand the distinction between individual-wise and experiment-wise error rates.
          \item Understand the strengths and weaknesses of Tukey-Kramer HSD and Dunnett's multiple comparison procedures.
          \item Understand what transformations are used for in a one-way ANOVA.
          \item Understand how to use the trial-and-error method to choose a power transformation.
          \item Present the results of a one-way ANOVA in an efficient, comprehensive, readable format.
       \end{Enumerate}
    \end{ChapObj}
  \vspace{-39pt}
\minitoc
\newpage

\lettrine{A}{ two-sample t-test} is used specifically when the means of two independent populations are compared. Many realistic experiments and samples result in the comparison of means from more than two independent populations. For example, consider the following situations:

\begin{Itemize}
  \item Determining if the mean volume of white blood cells of Virginia opossums (\emph{Didelphis virginiana}) differed by season in the same year (Woods and Hellgren 2003).
  \item Determining if the mean frequency of occurrence of badgers (\emph{Meles meles}) in plots differs between plots at different locations (Virgos and Casanovas 1999).
  \item Testing for differences in the mean total richness of macroinvertebrates  between the three zones of a river (Grubbs and Taylor 2004).
  \item Testing if the mean mass of porcupines (\emph{Erithizon dorsatum}) differs among months of summer (Sweitzer and Berger 1993).
  \item Testing if the mean clutch size of spiders differs among three types of parental care categories (Simpson 1995).
  \item Determining if the mean age of harvested deer (\emph{Odocoelius virginianus}) differs among deer harvested from Ashland, Bayfield, Douglas, and Iron counties.
\end{Itemize}

In each of these situations, the mean of a quantitative variable (e.g., age, frequency of occurrence, total richness, or body mass) is compared among two or more populations of a single factor variable (e.g., county, locations, zones, or season). A two-sample t-test cannot be used in these situations because more than two groups are compared. A one-way analysis of variance (or \textbf{one-way ANOVA}) may be used in these situations. The theory and application of one-way ANOVAs are discussed in this module.\footnote{This module depends heavily on the foundational material in \modref{chap:LMFoundations}.}

\warn{The two-sample t-test is used to determine if a significant difference exists between the means of two populations.}

\vspace{-12pt}
\warn{A one-way analysis of variance (ANOVA) is used to determine if a significant difference exists among the means of more than two populations.}


\section{Analytical Foundation}
The generic null hypothesis for a one-way ANOVA is
\[ H_{0}: \mu_{1} = \mu_{2} = \ldots = \mu_{I} \]
where $I$ is the total number of groups identified by the factor variable. From this, it is evident that the one-way ANOVA is a direct extension of the two-sample t-test (see \sectref{sect:2tTest}). The alternative hypothesis is complicated because not all pairs of means need differ for the null hypothesis to be rejected. Thus, the alternative hypothesis for a one-way ANOVA is ``wordy'' and is often written as
\[ H_{A}:\text{``At least one pair of means is different''} \]

Thus, a rejection of the null hypothesis in favor of this alternative hypothesis is a statement that \textit{some} difference in group means exists. It does not clearly indicate which group means differ. Methods to identify which group means differ are in \sectref{sect:MultComp}.

The simple and full models for the one-way ANOVA are the same as those for the two-sample t-test, except that there are $I>2$ means in the full model \figrefp{fig:LM1AOVModels}. Thus, $SS_{total}$, $SS_{within}$, and $SS_{among}$ are computed using the same formulas -- i.e., Equations \eqref{eqn:SStotal}, \eqref{eqn:SSwithin}, and \eqref{eqn:SSamong} -- except to note that $I>2$. The degrees-of-freedom are computed similarly -- i.e., $df_{Within}=n-I$ and $df_{Among}=I-1$. The MS, $F$, and p-value are also computed the same.\footnote{The MS, $F$, and p-value are computed the same in nearly every ANOVA table encountered in this class.}

<<LM1AOVModels, echo=FALSE, fig.cap="Immunoglobulin concentrations in Virginia opossums sampled from different seasons. The red horizontal line represents the simple model of a grand mean for both groups. The three blue horizontal lines represent the full model of separate means for each group.",fig.pos="!h">>=
opp <- read.csv("data/Opposums.csv")
opp$season <- factor(opp$season,levels=c("feb","may","nov"))

plot(imm~as.numeric(season),data=opp,pch=21,bg=col2rgbt("gray50",1/2),
     xlab="Season",ylab="Immunoglobulin Concentration",xlim=c(0.5,3.5),xaxt="n")
axis(1,at=c(1,2,3),labels=c("Feb","May","Nov"))
abline(h=mean(opp$imm),col="red",lwd=2)

mns <- tapply(opp$imm,opp$season,mean)
lines(c(0.8,1.2),c(mns[1],mns[1]),col="blue",lwd=2)
lines(c(1.8,2.2),c(mns[2],mns[2]),col="blue",lwd=2)
lines(c(2.8,3.2),c(mns[3],mns[3]),col="blue",lwd=2)
@

\vspace{-12pt}
\warn{The numerator df in a one-way ANOVA are $I-1$.}

\vspace{-12pt}
\warn{The denominator df in a one-way ANOVA are $n-I$.}

\subsection{One-way ANOVA in R}
\vspace{-12pt}
\subsubsection*{Data Format}
\vspace{-12pt}
As with a two-sample t-test, the data for a one-way ANOVA must be stacked \sectrefp{sect:DataStacked}. For example, the \dfile{Opposums.csv} (\href{https://github.com/droglenc/NCData/blob/master/Opposums.csv}{view}, \href{https://raw.githubusercontent.com/droglenc/NCData/master/Opposums.csv}{download}, \href{https://github.com/droglenc/NCData/blob/master/Opposums_meta.txt}{meta}) file contains the immunoglobulin concentration levels measured on Virginia opossums sampled from three different seasons. The structure of the data file indicates two variables -- \var{imm}, the immunoglobulin concentration levels, and \var{season}, the season the opossum was sampled -- for 27 opossums. In addition, the  structure indicates that the \var{season} variable is a factor with three levels. The display of several lines of the file shows the stacked nature of the data.
<<eval=FALSE>>=
opp <- read.csv("Opposums.csv")
@
\vspace{-8pt}
<<>>=
str(opp)
headtail(opp)
@

Recall that the levels of a factor variable are ordered alphabetically by default. In this example, the alphabetical ordering is acceptable; i.e., ``feb'', ``may'', and ``nov'' is both the alphabetic and natural order for these levels. Changing the order of the levels was described in \sectref{sect:RtTest}.


\subsubsection*{Fitting Model \& Results}
\vspace{-12pt}

<<echo=FALSE>>=
opp.lm <- lm(imm~season,data=opp)
opp.aov <- anova(opp.lm)
opp.lev <- levenesTest(opp.lm)
opp.ad <- adTest(opp.lm$residuals)
opp.out <- outlierTest(opp.lm)
@

A one-way ANOVA model is fit with \R{lm()} exactly as described for a two-sample t-test in \sectref{sect:RtTest}.\footnote{The \R{aov()} function can also be used. However, \R{aov()} calls \R{lm()} to make the calculations. For this reason, and the fact that \R{lm()} is more general and can be used for a wider variety of situations, only \R{lm()} is discussed here.}  For example, the very small p-value (\Sexpr{kPvalue(opp.aov[1,"Pr(>F)"],digits=3)}) below indicates that the full model of a separate mean for each group fits the data ``better'' than the simple model of one common mean. Thus, there is a significant difference in mean immunoglobulin level between at least one pair of the three seasons.
<<>>=
opp.lm <- lm(imm~season,data=opp)
anova(opp.lm)
@

The natural reaction at this point is to ask ``Which means are different?''. This question will be answered more completely in \sectref{sect:MultComp}. However, giving the saved linear model object to \R{fitPlot()} will produce a graphic to visually compare group means \figrefp{fig:LM1PlotMeans}.
<<LM1PlotMeans, fig.cap="Mean (with 95\\% CI) immunoglobulin concentrations in Virginia opossums from different seasons.">>=
fitPlot(opp.lm,xlab="Season",ylab="Immunoglobulin Concentration")
@

\section{Assumptions} \label{sect:OWAAssumptions}
A one-way ANOVA has the same assumptions as a two-sample t-test. The four assumptions are
\begin{Enumerate}
  \item independence of individuals within and among groups,
  \item equal variances among groups,
  \item normality of residuals within each group, and
  \item no outliers
\end{Enumerate}

\warn{The one-way ANOVA has four assumptions: independence among individuals, equal variances among groups, normality within groups, and no outliers.}

It is critical to the proper analysis and interpretation of one-way ANOVAs that the individuals are independent both within and among groups. In other words, there must be no connections between the individuals within a group or between individuals among groups. Examples of a lack of independence include applying multiple treatments to the same individual (e.g., treatment A in week 1, treatment B in week 2, etc.), having all related individuals within the same group (e.g., all siblings are in the same group), or having individuals that are not separated in space and time (e.g., the first four individuals receive treatment A, the second four individuals receive treatment B, etc., or four clustered individuals are in group A, four other clustered individuals are in group B, etc.). Violations of this assumption are  usually detected by careful consideration of the design of the data collection. Violations that are discovered after the data are collected cannot be corrected and the data have to be analyzed with techniques specific to dependent data. In other words, designing data collections with independence among individuals is critical and needs to be ascertained before the data are collected.

\warn{Independence of individuals is a critical assumption of one-way ANOVAs. Violations of this assumption cannot be corrected.}

The variances among groups must be equal because the estimate of $MS_{Within}$ is based on a pooling of estimates from the individual groups. In other words, if the variances among each group are equal, then the MS within each group is an estimate of the overall $MS_{Within}$. In this instance, combining the values from each group provides a robust estimate of the overall variance within groups.

The assumption of equal variances can be tested with Levene's homogeneity of variances test.\footnote{There are a wide variety of statistical tests for examining equality of variances. We will use the Levene's test in this class because it is common in the literature and simple to implement in most statistical software packages.}  The hypotheses tested by Levene's test are
\[ \begin{split}
   H_{0}&: \sigma_{1}^{2}=\sigma_{2}^{2}=\cdots=\sigma_{I}^{2} \\
   H_{A}&:\text{``At least one pair of variances is different''}
\end{split} \]

Thus, a p-value less than $\alpha$ means that the variances are not equal and the assumption of the one-way ANOVA has not been met.\footnote{Methods for ``working around'' this assumption are discussed in \sectref{sect:AOVTransformations}.}

In certain instances,\footnote{For example, if there is a large number of groups with a small number of individuals each or if only one individual per block-treatment combination is used.} Levene's test is not practical for examining the equality of variances. In these instances, the equality of variances may be visually examined with a boxplot of full model residuals by group. If the ``boxes'' on this boxplot are not roughly the same, then the equal variances assumption may be violated. This boxplot should only be used if Levene's test cannot be used to test for equal variances.

\warn{Equal variances among groups is a critical assumption of a one-way ANOVA. Violations of this assumption should be corrected.}

\vspace{-12pt}
\warn{The equal variance assumption is tested with Levene's test. P-values less than $\alpha$ indicate that the variances are not equal and the assumption was violated.}

The normality of residuals WITHIN each group is difficult to test because there may be (1) many groups being considered or (2) relatively few individuals in each group. Because most linear models are robust to slight departures from normality, it is often assumed that if the full model residuals are approximately normally distributed, then the residuals within each group are also normally distributed. Thus, the normality assumption for one-way ANOVA reduces to examining the normality of full model residuals together (i.e., not separated by groups).

The normality of residuals may be tested with the Anderson-Darling Normality Test.\footnote{There are also a wide variety of normality tests. Some authors even argue against the use of hypothesis tests for testing normality and suggest the use of graphical methods instead. For simplicity, the Anderson-Darling normality test will be used throughout this book.}  In this instance, the hypotheses tested by an Anderson-Darling test are
\[ \begin{split}
   H_{0}&: \text{``Residuals are normally distributed''} \\
   H_{A}&:\text{``Residuals are not normally distributed''} \\
\end{split} \]
An Anderson-Darling p-value greater than $\alpha$ indicates that the residuals appear to be normally distributed and the normality assumption is met. An Anderson-Darling p-value less than $\alpha$ suggests that the normality assumption has been violated.

\warn{The normality assumption is tested with the Anderson-Darling test of the full model residuals. P-values less than $\alpha$ indicate that the residuals are not normally distributed and the normality assumption was violated.}

As mentioned before, the one-way ANOVA is robust to slight departures from normality within groups. Some authors argue that a one-way ANOVA can still be used if the residuals from the one-way ANOVA fit are, at least, not strongly skewed and the sample size is moderately large. Thus, if the Anderson-Darling normality test suggests non-normality in the residuals, one should construct a histogram of the residuals to determine if they are not strongly skewed. If the residuals are strongly skewed, then the methods of \sectref{sect:AOVTransformations} should be considered. If the residuals are only slightly skewed and the other assumptions have been met, then one can proceed relatively confidently with a one-way ANOVA.

\warn{A one-way ANOVA is robust to slight violations of the normality assumption. Severe violations of this assumption should be corrected.}

The one-way ANOVA is very sensitive to outliers. Outliers should be corrected if possible (usually if there is a data transcription or entry problem). The outlier should be deleted if it is determined that the outlier is clearly in error or is not part of the population of interest. If the outlier is not corrected or deleted, then the relative effect of the outlier on the analysis should be determined by completing the analysis with and without the outlier present. Any differences in results or interpretations due to the presence of the outlier should be clearly explained to the reader.

\warn{A one-way ANOVA is very sensitive to outliers.}

\vspace{-12pt}
\warn{Outliers that are obvious errors should be fixed or deleted. The effect of outliers that are not errors should be assessed by completing the one-way ANOVA with and without the outlier in the data set.}

Outliers may be detected by visual examination of a residual plot. In addition, potential outliers can be more objectively detected with Studentized residuals, which is a residual divided by the standard deviation of the residual. Because residuals have a mean of zero, this calculation essentially computes how many standard deviations an individual residual is from the group mean. Because this is the standard definition of a t test statistic, Studentized residuals have the property of following a t distribution with $n-I$ df.

One problem with Studentized residuals is that the standard deviation of the residual is inflated if the individual is indeed an outlier. One method of correcting this problem is to compute the standard deviation of the residual with that residual removed from the data. This standard deviation is called the ``leave-one-out'' standard deviation and is common practice for many calculations aimed at finding potential outliers. A Studentized residual computed with the ``leave-one-out'' standard deviation is called an externally Studentized residual.\footnote{Some authors call these jackknife residuals.}  Externally Studentized residuals will be used exclusively in this course and will simply be called Studentized residuals.

The main advantage of Studentized residuals is that their distribution is well known -- i.e., they follow a t distribution with degrees-of-freedom equal to $df_{Within}-1$ or $n-I-1$.\footnote{The extra one is subtracted because of the ``leave-one-out'' practice.}  This allows construction of a hypothesis test to determine whether an individual can be considered to be a significant outlier or not. The p-value for this hypothesis test is calculated by converting the Studentized residual to a two-tailed p-value using a t distribution.

This method of testing for outliers is ``dangerous'' because the researcher will ``sort through'' all of the residuals to focus on the most extreme residual. So, in essence, the researcher constructs $n$ hypothesis tests, but only focuses on one. This type of ``testing'' leads to a difficulty called the ``problem of multiple comparisons'', which is discussed in much more detail in \sectref{sect:MultComp}. The multiple comparisons problem can be conservatively corrected with a Bonferroni correction, which constructs an adjusted p-value by multiplying the original p-value by the number of comparisons made (in this case $n$). If the Bonferroni adjusted p-value for the most extreme residual is less than $\alpha$, then that individual is considered to be a significant outlier and should be flagged for further inspection as described above.


\subsection{Assumption Checking in R}
\vspace{-12pt}
All plots and tests of assumptions can be completed by submitting the saved \R{lm} object to \R{transChooser()}. A residual plot and histogram of residuals will be produced. In RStudio, a "gear icon" will appear in the upper-left corner of this plot. Open this gear icon and select "Use Boxplot for Residuals" and, to show the assumptions tests results, "Show Test Results." With this the p-values from the Levene's, Anderson-Darling, and outlier tests\footnote{Note that significant outliers, as identified with \R{outlierTest()}, will be marked with the observation number on the default residual plot from \R{residPlot()}.} will be shown on the plot \figrefp{fig:LM1AOVResidPlot}.\footnote{Note that the individual tests can be constructed with \R{levenesTest()}, \R{adTest()}, and \R{outlierTest()} and the residual plot can be constructed with \R{residPlot()}.}
<<eval=FALSE>>=
transChooser(opp.lm)
@

Thus, in this example, it appears that the variances among the three seasons are equal (\Sexpr{kPvalue(opp.lev[1,"Pr(>F)"],digits=3)}),\footnote{Note also that the ``box'' heights in \figref{fig:LM1AOVResidPlot}-Left are ``roughly'' equal, but that the Levene's test result is the definitive answer about equal variances in this instance.} the residuals are not non-normal (\Sexpr{kPvalue(opp.ad$p.value,digits=3)}) or strongly skewed, and there were no significant outliers (\Sexpr{kPvalue(opp.out$bonf.p,digits=3)}).\footnote{ndividual 19 had an absolute value of the Studentized residual of \Sexpr{formatC(opp.out$rstudent,format="f",digits=3)} and a Bonferroni-adjusted \Sexpr{kPvalue(opp.out$bonf.p,digits=3)}. Note that R will not show p-values greater than 1 and returns an \R{NA} instead. There is also a note at the beginning of this output that shows that no Bonferroni p-value is $<$ 1. This adjusted p-value is much greater than $\alpha$ and, thus, there is no indication of an outlier in these data.} Therefore, the assumptions of a one-way ANOVA have been met for these data.

\begin{figure}[h]
  \centering
  \includegraphics[width=5in]{FigsStatic/LM1AOVResidPlot.jpg}
  \caption{Residual plot (Left) and histogram of residuals (Right) for the one-way ANOVA of immunoglobulin concentrations in Virginia opossums sampled from different seasons.}\label{fig:LM1AOVResidPlot}
\end{figure}



\section{Example Analyses I}
\vspace{-12pt}
\subsection{Tomatoes-Nematodes I} \label{sect:OWAEx1A}
<<echo=FALSE>>=
TomatoNematode <- read.csv("data/TomatoNematode.csv")
TomatoNematode$density <- factor(TomatoNematode$density)
@

Nematodes are microscopic worms found in soil that may negatively affect the growth of plants through their trophic dynamics. Tomatoes are a commercially important plant species that may be negatively affected by high densities of nematodes in culture situations.

A science fair student designed an experiment to determine the effect of increased densities of nematodes on the growth of tomato seedlings (i.e., an indicator of plant health). The student hypothesized that nematodes would negatively affect the growth of tomato seedlings -- i.e., growth of seedlings would be lower at higher nematode densities. The statistical hypotheses to be examined were
\[ \begin{split}
   H_{0}&: \mu_{0} = \mu_{1000} = \mu_{5000} = \mu_{10000} \\
   H_{A}&:\text{``At least one pair of means is different''}
\end{split} \]

where the subscripts identify densities of nematodes (see below).

\subsubsection*{Data Collection}
\vspace{-12pt}
The student had 16 pots of a homogeneous soil type in which he ``stocked'' a known density of nematodes. The densities of nematodes used were 0, 1000, 5000, or 10000 nematodes per pot. The density of nematodes to be stocked in each pot was randomly assigned. After stocking the pots with nematodes, tomato seedlings, which had been selected to be as nearly identical in size and health as possible, were transplanted into each pot. The exact pot that a seedling was transplanted into was again randomly selected. Each pot was placed under a growing light in the same laboratory and allowed to grow for six weeks. Watering regimes and any other handling necessary during the six weeks was kept the same as possible among the pots. After six weeks, the plants were removed from the growing conditions and the growth of the seedling (in cm) from the beginning of the experiment was recorded.

\subsubsection*{Exploratory Data Analysis and Assumption Checking}
\vspace{-12pt}
It appears that tomato seedling growth may differ among nematode densities, with growth apparently suppressed at the two highest densities \figrefp{fig:OWAEx1Plot1}. The dispersion among individuals appears to be similar among the four groups \figrefp{fig:OWAEx1Plot1}.

<<OWAEx1Plot1, echo=FALSE, fig.cap="Boxplot of tomato seedling growth at each nematode density.", fig.pos="!h">>=
boxplot(growth~density,data=TomatoNematode,xlab="Nematode Density",ylab="Growth (inches)")
@

<<echo=FALSE>>=
tn.lm <- lm(growth~density,data=TomatoNematode)
tn.lev <- levenesTest(tn.lm)
tn.out <- outlierTest(tn.lm)
tn.ad <- adTest(tn.lm$residuals)
@
Individuals appear to be independent in this experiment because there does not appear to be any connection among pots either within (this assumes that the pots were randomly placed in the laboratory) or among treatments. Variances among the treatments appear to be approximately equal (Levene's \Sexpr{kPvalue(tn.lev[1,"Pr(>F)"],digits=3)}; \figref{fig:OWAEx1Plot2}-Left), the residuals appear to be approximately normally distributed (Anderson-Darling \Sexpr{kPvalue(tn.ad$p.value,digits=3)}) and the histogram does not indicate any major skewness (\figref{fig:OWAEx1Plot2}-Right), and there does not appear to be any major outliers in the data (outlier test \Sexpr{kPvalue(tn.out$bonf.p,digits=3)}; \figref{fig:OWAEx1Plot2}). The analysis will proceed because the major assumptions of the one-way ANOVA have been met.

\begin{figure}[h]
  \centering
  \includegraphics[width=5in]{FigsStatic/OWAEx1Plot2.jpg}
  \caption{Boxplot (Left) and histogram (Right) of residuals from the initial fit of the one-way ANOVA model to the tomato seedling growth at each nematode density.}\label{fig:OWAEx1Plot2}
\end{figure}

\subsubsection*{Results}
\vspace{-12pt}
There appears to be a significant difference in mean tomato seedling growth among the four treatments (\Sexpr{kPvalue(anova(tn.lm)[1,"Pr(>F)"],digits=3)}; \tabref{tab:OWAEx1ANOVA}). The plot of each treatment mean with 95\% confidence intervals indicates that the mean growth at the two lowest nematode densities probably are not different and the mean growth at the two highest nematode densities probably are not different, but the mean growth at the two lowest nematode densities are different from the two highest nematode densities \figrefp{fig:OWAEx1Means1}.\footnote{Objective methods for determining which treatment means are significantly different are discussed in \sectref{sect:MultComp}.}

\begin{table}[h]
  \centering
  \caption{ANOVA results for tomato seedling growth at four nematode densities.}\label{tab:OWAEx1ANOVA}
<<echo=FALSE, background='white'>>=
kANOVA(tn.lm)
@
\end{table}

<<OWAEx1Means1, echo=FALSE, fig.cap="Mean tomato seedling growth with 95\\% confidence interval at each nematode density from the fit of the one-way ANOVA model.">>=
fitPlot(tn.lm,xlab="Nematode Density",ylab="Growth (inches)")
@

\subsubsection*{Conclusion}
\vspace{-12pt}
The student's hypothesis was generally supported; however, it does not appear that tomato seedling growth is negatively affected for all increases in nematode density. For example, seedling growth declined for an increase in nematode density from 1000 to 5000 per pot but not for increases from 0 to 1000 nematodes per pot or from 5000 to 10000 nematodes per pot.

It can be concluded that the different nematode densities caused the differences in tomato seedling growth because the individual seedlings were randomly allocated to treatment groups and all other variables were controlled. However, the inferences cannot be extended to a general population of tomatoes because the 16 seedlings used in the experiment were not randomly chosen from the population of seedlings.

From these results, the experimenter might want to re-run the experiment for densities between 1000 and 5000 nematodes per pot in an attempt to find a ``critical'' nematode density below which there is very little affect on growth and above which there is a significant negative affect on growth.

\subsubsection*{Appendix -- R Commands}
\vspace{-12pt}
\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm,commandchars=\\\{\}]
TomatoNematode <- read.csv("TomatoNematode.csv")
TomatoNematode$density <- factor(TomatoNematode$density)
boxplot(growth~density,data=TomatoNematode,xlab="Nematode Density",ylab="Growth (inches)")
tn.lm <- lm(growth~density,data=TomatoNematode)
transChooser(tn.lm)
anova(tn.lm)
fitPlot(tn.lm,xlab="Nematode Density",ylab="Growth (inches)")
\end{Verbatim}

\subsection{Moose-Pines I} \label{sect:OWAEx2A}
\vspace{-12pt}
\subsubsection*{Introduction}
\vspace{-12pt}
<<echo=FALSE>>=
MooseBrowse <- read.csv("data/MooseBrowse.csv")
MooseBrowse$treat <- factor(MooseBrowse$treat,
                            levels=c("Control","Fertilized","Clipped","Shaded"))
@

The availability of resources for growth is believed to have a substantial impact on the chemical defense of plants against herbivores. However, the means by which resource availability affects different plant traits, and the way in which these factors in turn affect diet selection by herbivores are not well understood. Edenius (1993) addressed the relation between plant biomass, morphology, and tissue nutritional quality and browsing by moose (\emph{Alces alces}) on Scots pine (\emph{Pinus sylvestris}).

\vspace{-12pt}
\subsubsection*{Data Collection}
\vspace{-12pt}
In one part of this study, Edenius examined the effect of three different experimental treatments related to nutrient and light availability on various characteristics of the Scots pine. In this example, the characteristic of the Scots pine that will be examined is tree height (measured in cm). The four treatments were labeled as ``Fertilized'', ``Clipped'', ``Shaded'', and ``Control.''  In the fertilized treatment, 60 g of nitrogen (ammonium nitrate) was applied to the soil within a 2-m radius of each tree at the beginning of the growing season. In the clipped treatment, all shoots produced in the previous growing year were removed. In the shaded treatment, the top- and lateral-most branches were covered with a shade cloth that reduced the light intensity by 50\% in the 400-700 nm wavelengths. Finally, a fourth group of trees were maintained without any manipulation as a control.

A total of 140 unbrowsed trees that were approximately 1.4 m in height were specifically selected for use in the experiment. The trees were randomly allocated to the four treatments such that each group had 35 trees in it. Selected trees were separated by at least 5 m to avoid interference among individual trees and, thus, treatment groups. Trees were allowed to grow for one full growing season and then were measured for height. Edenius, wanted to determine if there was a significantly different mean height among the treatments. Thus,
\[ \begin{split}
   H_{0}&: \mu_{Fert} = \mu_{Clip} = \mu_{Shade} = \mu_{Control} \\
   H_{A}&:\text{``At least one pair of means is different''}
\end{split} \]

One-way ANOVA will be used to identify if any significant differences exist among the treatment means.


\vspace{-12pt}
\subsubsection*{Exploratory Data Analysis and Assumption Checking}
\vspace{-12pt}
It appears that tree height differs among treatments, with the clipped group being substantially smaller than the other three groups (\tabref{tab:OWAEx2DescStat}, \figref{fig:OWAEx2Plot1}). There is also some indication that the variances might be different as the standard deviation for the ``control'' group appears to be substantially larger than the standard deviation for the ``shaded'' group \tabrefp{tab:OWAEx2DescStat}.

\begin{table}
  \centering
  \caption{Descriptive statistics for height of Scots pines in four treatment groups.}\label{tab:OWAEx2DescStat}
<<echo=FALSE, background='white'>>=
print(Summarize(height~treat,data=MooseBrowse),row.names=FALSE)
@
\end{table}

<<OWAEx2Plot1, echo=FALSE, fig.width=7, fig.height=2.5,out.width='.7\\linewidth', fig.cap="Histograms of Scots pine height for four treatment groups.">>=
hist(height~treat,data=MooseBrowse,xlab="Height (cm)",ncol=4,nrow=1)
@

<<echo=FALSE>>=
mb.lm <- lm(height~treat,data=MooseBrowse)
mb.lev <- levenesTest(mb.lm)
mb.ad <- adTest(mb.lm$residuals)
mb.out <- outlierTest(mb.lm)
@

The random allocation of trees to the treatments and the realization that applying the treatment to any one tree has no affect on any other tree implies that there is independence both within a treatment and among treatments. Variances among the treatments may be non-constant (Levene's \Sexpr{kPvalue(mb.lev[1,"Pr(>F)"],digits=3)}), though the residual plot (\figref{fig:OWAEx2Plot2}-Left) does not indicate any extreme differences in variances and no transformation (see \sectref{sect:AOVTransformations}) corrected this problem. The residuals from the initial model fit appear to be approximately normal (Anderson-Darling \Sexpr{kPvalue(mb.ad$p.value,digits=3)}). None of the individuals appeared to be a significant outlier (outlier test \Sexpr{kPvalue(mb.out$bonf.p,digits=3)}). The one-way ANOVA analysis will continue as the assumptions either appear to be met, are not grossly unmet, or no reasonable solution to the problems exists.

\begin{figure}[h]
  \centering
  \includegraphics[width=5in]{FigsStatic/OWAEx2Plot2.jpg}
  \caption{Boxplot (Left) and histogram (Right) of residuals from the initial fit of the one-way ANOVA model to the Scots pines heights at each treatment level.}\label{fig:OWAEx2Plot2}
\end{figure}

\subsubsection*{Results}
\vspace{-12pt}
There appears to be a significant difference in mean tree growth among the four treatments (\Sexpr{kPvalue(anova(mb.lm)[1,"Pr(>F)"],digits=3)}; \tabref{tab:OWAEx2ANOVA}). Plots for each treatment group indicate that mean height for the clipped treatment is lower than mean height in all other treatments, mean height in the fertilized treatment may be greater than mean height in all other treatments, and mean heights in the shaded and control groups do not differ \figrefp{fig:OWAEx2Means1}.

\begin{table}[h]
  \centering
  \caption{ANOVA results for tree growth for four treatments.}\label{tab:OWAEx2ANOVA}
\vspace{-12pt}
<<echo=FALSE, background='white'>>=
kANOVA(mb.lm)
@
\end{table}

<<OWAEx2Means1, echo=FALSE, fig.cap="Mean Scots pine height with 95\\% confidence interval for each treatment group from the initial fit of the one-way ANOVA model.", fig.width=5, out.width='.6\\linewidth'>>=
fitPlot(mb.lm,xlab="Treatment",ylab="Tree Height (cm)")
@

\vspace{-12pt}
\subsubsection*{Conclusion}
\vspace{-12pt}
The clipped treatment resulted in significantly lower growth of Scots pine. The fertilized treatment may have produced slightly taller trees than the control group.

It can be concluded that the different treatments caused the differences in tree growth because the individual trees were randomly allocated to treatment groups and all other variables were controlled. However, the inferences cannot be extended to a general population of trees because the 140 trees used in the experiment were not randomly chosen from the population of trees.

\vspace{-12pt}
\subsubsection*{Appendix -- R Commands}
\vspace{-12pt}
\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm,commandchars=\\\{\}]
MooseBrowse <- read.csv("MooseBrowse.csv")
MooseBrowse$treat <- factor(MooseBrowse$treat,
   levels=c("Control","Fertilized","Clipped","Shaded"))
Summarize(height~treat,data=MooseBrowse)
hist(height~treat,data=MooseBrowse,xlab="Treatment",ylab="Tree Height (cm)")
mb.lm <- lm(height~treat,data=MooseBrowse)
transChooser(mb.lm)
anova(mb.lm)
fitPlot(mb.lm,xlab="Treatment",ylab="Tree Height (cm)")
\end{Verbatim}


\vspace*{6pt}
\section{Multiple Comparisons} \label{sect:MultComp}
\vspace{-12pt}
A significant result (i.e., reject $H_{0}$) in a one-way ANOVA indicates that the means of at least one pair of groups differ. At this time, it is not known whether all means are different, two means are equivalent but different from all other means, all means are equivalent except for one pair, or any other possible combination of equivalencies and differences. Thus, once a significant overall result is obtained in a one-way ANOVA, specific follow-up analyses are needed to identify which pairs of means are significantly different.

\warn{A one-way ANOVA only indicates that at least one pair of means differ. Follow-up analyses are required to specifically determine which pairs of means are different.}

\vspace{-12pt}
\subsection{The Problem}
\vspace{-12pt}
The most obvious solution for identifying which pairs of means are different is to perform multiple two-sample t-tests on all pairs of groups. Unfortunately, this seemingly simple answer has at least two major difficulties. First, the number of two-sample t-tests needed increases dramatically with increasing numbers of groups \tabrefp{tab:MCProblem}. Second, the probability of incorrectly concluding that at least one pair of means differs when no pairs actually differ increases dramatically with increasing numbers of groups \tabrefp{tab:MCProblem}. Of these two difficulties, the second is much more problematic and needs to be better understood.

\begin{table}[ht]
  \centering
  \caption{Relationship between the number of groups in an analysis, the number of pairs of means that would need to be tested and the experiment-wise error rate for two different rejection criteria.}\label{tab:MCProblem}
  \begin{tabular}{cccc}
    \hline\hline
    \widen{0}{5}{Groups} & Pairs to Test &  &  \\
    \widen{-2}{0}{(I)} & (k) & $\alpha=0.05$ & $\alpha=0.10$ \\
    \hline
    \widen{0}{5}{2} & 1 & 0.05 & 0.10 \\
    \widen{0}{0}{3} & 3 & 0.1426 & 0.2710 \\
    \widen{0}{0}{4} & 6 & 0.2649 & 0.4686 \\
    \widen{0}{0}{5} & 10 & 0.4013 & 0.6513 \\
    \widen{-2}{0}{6} & 15 & 0.5367 & 0.7941 \\
    \hline\hline
  \end{tabular}
\end{table}

In any one comparison of two means the probability of incorrectly concluding that the means are different when they are actually not different is $\alpha$. This incorrect conclusion is called a Type I error and $\alpha$ is called the \emph{individual-wise Type I error rate} because it relates to only one comparison of a pair of means.

\defn{Individual-wise error rate}{The probability of a Type I error in a single comparison of two means. The individual-wise error rate is set at $\alpha$.}

\vspace{-12pt}
\warn{A Type I error is rejecting $H_{0}$ when $H_{0}$ is actually true. In a two-sample t-test, a Type I error is concluding that two means are significantly different when in fact they are not.}

If three pairs of means are simultaneously compared, as would happen if there were three groups \tabrefp{tab:MCProblem}, then the probability that at least one decision for a pair of these means will be incorrect increases. The probability that \textbf{at least} one Type I error occurs in simultaneous comparisons is called the \emph{experiment-wise error rate} because it involves all comparisons in the experiment at hand. It is very important that you notice the words \emph{at least} in the previous sentences. In three comparisons, the incorrect conclusion could be for the first pair, the second pair, the third pair, the first and second pair, the first and third pair, the second and third pair, or all three pairs!!  Because of this, the experiment-wise error rate is computed as the complement of the probability of no errors, or $1-(1-\alpha)^{k}$, where $k$ is the number of paired comparisons to be made.

In \tabref{tab:MCProblem}, it is evident that, with $\alpha=0.05$ and six treatments, the probability of concluding that at least one pair of means is different when there are no true differences among means is over 50\%. In other words, it is nearly a coin flip that at least one error will be made in this situation. Six treatments is not a large set of groups to compare and this level of error is unacceptable and must be reduced.

\defn{Experiment-wise error rate}{The probability of at least one Type I error in a set of comparisons of two means. The experiment-wise error rate depends on the number of comparisons made and is calculated with $1-(1-\alpha)^{k}$, where $k$ is the number of paired comparisons to be made.}

\vspace{-12pt}
\warn{The experiment-wise error rate increases dramatically with increasing numbers of treatment groups.}

\subsection{Correction Methods}
\vspace{-12pt}
The statistical literature is full of various methods that have been designed to attempt to control the experiment-wise error rates. For simplicity, only three methods will be considered in this book. The Tukey-Kramer honestly significantly different (i.e., Tukey's HSD) method controls the experiment-wise error rate at a desired level (i.e., $\alpha$) when the group sample sizes are the same and is slightly conservative if the group sample sizes are different. The Tukey's HSD method is the preferred multiple comparison method when all pairs of means are being compared. Dunnet's method is used to compare all groups to a specific control group. Dunnet's method does not make all pairwise comparisons, which increases statistical power (i.e., greater probability of identifying a true difference in means) compared to the Tukey's HSD method when comparing to a control group. Thus, even though both methods control the experiment-wise error rate, Dunnet's method should be used over the Tukey's HSD method when comparisons are made to a specific control group. The third method to control experimentwise error rates is discussed in \modref{chap:LMRegression2}.

\warn{Use Tukey's HSD method when comparing all pairwise means.}

\vspace{-12pt}
\warn{Use Dunnett's method when comparing all means to a single control group.}

\subsection{Multiple Comparisons in R}
\subsubsection*{Tukey's HSD}
<<echo=FALSE>>=
opp.mc <- glht(opp.lm,mcp(season="Tukey"))
opp.ci <- confint(opp.mc)
@

Tukey's HSD procedure is applied using \R{glht()} from the \R{multcomp} package. This function requires a saved \R{lm()} object as its first argument and the \R{mcp()} function as its second argument. The factor to be considered must be ``set equal'' to \R{"Tukey"} in \R{mcp()} to obtain Tukey's HSD correction. The results of \R{glht()} should be assigned to an object that is then submitted to \R{summary()} to extract the adjusted p-values for all comparisons or \R{confint()} to find the confidence intervals for the differences in means for all pairs of groups. For example, the results for the opossum data confirm that mean immunoglobulin for February and November and May and November are significantly different, whereas February and May are not significantly different.\footnote{This result is ``obtained'' by comparing the adjusted p-values to $\alpha$ or by noting which confidence intervals for the differences in means do not contain zero.} In fact, the mean immunoglobulin concentrations for opossums sampled in November appears to be between \Sexpr{formatC(-1*opp.ci$confint["nov - feb","upr"],format="f",digits=3)} and \Sexpr{formatC(-1*opp.ci$confint["nov - feb","lwr"],format="f",digits=3)} lower than for opossums sampled in February and between \Sexpr{formatC(-1*opp.ci$confint["nov - may","upr"],format="f",digits=3)} and \Sexpr{formatC(-1*opp.ci$confint["nov - may","lwr"],format="f",digits=3)} lower than for opossums sampled in May.\footnote{The results from \R{summary()} and \R{confint()} on a \R{glht()} object is overly verbose. Thus, the results have been condensed for printing in this book.}
<<eval=FALSE>>=
opp.mc <- glht(opp.lm,mcp(season="Tukey"))
summary(opp.mc)
@
\vspace{-14pt}
<<echo=FALSE>>=
kGLHT(opp.mc,"hypothesis")
@
<<eval=FALSE>>=
confint(opp.mc)
@
\vspace{-14pt}
<<echo=FALSE>>=
kGLHT(opp.mc,"confidence")
@

\subsubsection*{Dunnett's method}
Dunnett's procedure may also be applied using \R{glht()} with the factor variable in \R{mcp()} ``set equal'' to \R{"Dunnett"}. For example, the results below indicate that the mean immunoglobulin levels for opossums in May is not significantly different from opossums in February but the mean for opossums in November is significantly different from opossums in February.
<<results="hide">>=
opp.mc2 <- glht(opp.lm,mcp(season="Dunnett"))
summary(opp.mc2)
@
\vspace{-14pt}
<<echo=FALSE>>=
kGLHT(opp.mc2,"hypothesis")
@
<<eval=FALSE>>=
confint(opp.mc2)
@
\vspace{-20pt}
<<echo=FALSE>>=
kGLHT(opp.mc2,"confidence")
@

It is vitally important to note that all other groups will be compared to the group that is the first level in the factor variable. If the ``base'' group is not the first level of the factor variable, then the levels will need to be changed with \R{factor()} as shown in \sectref{sect:RtTest}. Suppose, for example, that you wanted ``may'' to be the group that ``feb'' and ``nov'' would be compared to. The factor would then need to be re-leveled, a new linear model fit and saved, and this new model sent to \R{glht()}.
<<results="hide">>=
opp$season1 <- factor(opp$season,levels=c("may","feb","nov"))
opp.lm2 <- lm(imm~season1,data=opp)
opp.mc3 <- glht(opp.lm2,mcp(season1="Dunnett"))
summary(opp.mc3)
@
\vspace{-14pt}
<<echo=FALSE>>=
kGLHT(opp.mc3,"hypothesis")
@

Note that using the Dunnett's procedure is unwarranted in this example -- it is used here for the sole purpose of illustrating the method.

\vspace{-6pt}
\subsubsection*{Graphing Significance Results}
\vspace{-12pt}
Multiple comparison results are often reported as "significance letters" on a plot of group means (usually with corresponding confidence intervals). Significance letters are assigned such that group means with the same letter are considered statistically the same (i.e., insignificant) and group means with different letters are considered statistically different (i.e., significant). The Tukey HSD results for the opossum data from above indicated that February and May should have the same letter (e.g., ``a'') and November should have a different letter (e.g., ``b'').

The plot of the group means is constructed with \R{fitPlot()} as illustrated previously. Significance letters are added to this plot with \R{addSigLetters()}. The first argument to \R{addSigLetters()} is the saved \R{lm()} object. The \R{lets=} argument is a character vector containing the letters to be placed next to each group mean, in the order that the group means are plotted. The \R{pos=} argument contains a numeric vector of positions that describe the position the letter should be placed relative to the point, with \R{1}=``below'', \R{2}=``left-of'', \R{3}=``above'', and \R{4}=``right-of''.\footnote{Note that the numbers are clockwise around the point beginning below the point.}  Finding ``good'' \R{pos} values may take some trial-and-error. \figref{fig:OWAEx1Means3} was constructed with the code below.

\vspace{-6pt}
<<OWAEx1Means3, fig.cap="Mean tomato seedling growth with 95\\% confidence interval at each nematode density from the initial fit of the one-way ANOVA model. Means with the same letter are not significantly different.">>=
fitPlot(opp.lm,xlab="Season",ylab="Immunoglobulin level")
addSigLetters(opp.lm,lets=c("a","a","b"),pos=c(2,4,4))
@

\section{Example Analyses II}
\vspace{-12pt}
\subsection{Tomatoes-Nematodes II}
\vspace{-12pt}
In \sectref{sect:OWAEx1A} the growth of tomato plants relative to the density of nematodes was examined. The one-way ANOVA results indicated that there was a significant difference in mean plant growth among the four densities of nematodes examined. Tukey's HSD procedure is used here to determine which pairs of groups means differ.

It appears that mean growth at densities 0 and 1000 are not significantly different, 0 and 5000 are different, 0 and 10000 are different, 1000 and 5000 are different, 1000 and 10000 are different, and 5000 and 10000 are not different (\tabref{tab:OWAEx1HSD}, \figref{fig:OWAEx1Means2}).\footnote{Recall that two means are considered different if the adjusted p-value is less than $\alpha$.}

\begin{table}[h]
  \centering
  \caption{Tukey's multiple comparisons for the Tomato - Nematode data.}\label{tab:OWAEx1HSD}
\vspace{-12pt}
<<echo=FALSE, background='white'>>=
kGLHT(summary(glht(tn.lm, mcp(density="Tukey"))))
@
\end{table}

<<OWAEx1Means2, echo=FALSE, fig.cap="Plot of group means versus treatment levels with means that are statistically the same marked with the same letter.">>=
fitPlot(tn.lm,xlab="Treatment",ylab="Tree Height (cm)")
addSigLetters(tn.lm,c("a","a","b","b"),pos=c(2,4,2,4))
@

\subsubsection*{Appendix -- R commands}
\vspace{-12pt}
\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm,commandchars=\\\{\}]
tn.mc <- glht(tn.lm, mcp(density="Tukey"))
summary(tn.mc)
confint(tn.mc)
fitPlot(tn.lm,xlab="Treatment",ylab="Tree Height (cm)")
addSigLetters(tn.lm,lets=c("a","a","b","b"),pos=c(2,4,2,4))
\end{Verbatim}

\subsection{Moose-Pines II}
\vspace{-12pt}
This example is a follow-up analysis to the second example in \sectref{sect:OWAEx2A}. Only those sections that would be modified to include multiple comparison results are shown here. Thus, a full analysis would be a combination of what was shown in \sectref{sect:OWAEx2A} and what is shown here.

\vspace{-6pt}
\subsubsection*{Data Collection}
\vspace{-12pt}
One-way ANOVA will be used to identify if significant differences exist among the means of the treatment groups. If a significant difference is identified, then Tukey's HSD method will be used to determine which pairs of treatment means are different.\footnote{Dunnett's method is not used here, even though there is a control group, because interest is in comparing all pairs of treatments, not just all pairs of treatments with the control group.}

\vspace{-6pt}
\subsubsection*{Results}
\vspace{-12pt}
There appears to be a significant difference in mean tree growth among the four treatments (\Sexpr{kPvalue(anova(mb.lm)[1,"Pr(>F)"],digits=3)}; \tabref{tab:OWAEx2ANOVA}). Trees in the clipped treatment are significantly shorter then trees in the other three treatments \tabrefp{tab:OWAEx2HSD}. The trees in the shaded treatment are shorter than trees in the fertilized treatment but statistically similar to trees in the control treatment \tabrefp{tab:OWAEx2HSD}. Trees in the control treatment are statistically similar to trees in both the shaded and fertilized treatments \tabrefp{tab:OWAEx2HSD}.\footnote{This result for the shaded, control, and fertilized treatments is a fairly common occurrence - i.e., the middle of the ordered treatments is statistically similar to both the treatment just bigger and the treatment just smaller, but the two treatments on the ends are statistical different. So, sometimes the results lead to confusing but ultimately correct statements such as --- ``the control treatment is equal to both the shaded and fertilized treatments but the shaded and fertilized treatments are different.''}  The results of this analysis are summarized in \figref{fig:OWAEx2Means2}.

\begin{table}[h]
  \centering
  \caption{Tukey's adjusted confidence intervals for mean tree growth for four treatments. Note that the output was modified to save space.}\label{tab:OWAEx2HSD}
\vspace{-12pt}
<<echo=FALSE, background='white'>>=
kGLHT(summary(glht(mb.lm, mcp(treat="Tukey"))))
@
\end{table}

<<OWAEx2Means2, echo=FALSE, fig.cap="Plot of group means versus treatment levels with means that are statistically the same marked with the same letter.",fig.width=5,out.width='.6\\linewidth'>>=
fitPlot(mb.lm,xlab="Treatment",ylab="Tree Height (cm)")
addSigLetters(mb.lm,c("bc","c","a","b"),pos=c(2,4,2,4))
@

\vspace{-6pt}
\subsubsection*{Appendix -- R commands}
\vspace{-12pt}
\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm,commandchars=\\\{\}]
mb.mc <- glht(mb.lm, mcp(treat="Tukey"))
summary(mb.mc)
confint(mb.mc)
fitPlot(mb.lm,xlab="Treatment",ylab="Tree Height (cm)")
addSigLetters(mb.lm,lets=c("bc","c","a","b"),pos=c(2,4,2,4))
\end{Verbatim}


\section{Transformations} \label{sect:AOVTransformations}
\vspace{-12pt}
If the assumptions of a one-way ANOVA are violated, then the results of the one-way ANOVA are inappropriate. Fortunately, if the equality of variances or normality assumptions are violated, then corrective measures can usually be taken so that appropriate results can be obtained. The most common corrective measure is to transform the response variable to a scale where the variances among treatment groups are equal and the individuals within treatment groups are normally distributed.

Besides the obvious reason related to assumption violations, Fox (1997) gave four arguments for why data that is skewed or shows a non-constant variance should be transformed:

\vspace{-12pt}
\begin{Itemize}
  \item Highly skewed distributions are difficult to examine because most of the observations are confined to a small part of the range of the data.
  \item Apparently outlying individuals in the direction of the skew are brought in towards the main body of the data when the distribution is made more symmetric. In contrast, unusual values in the direction opposite to the skew can be hidden prior to transforming the data.
  \item Linear models summarize distributions based on means. The mean of a skewed distribution is not, however, a good summary of its center.
  \item When a variable has very different degrees of variation in different groups, it becomes difficult to examine the data and to compare differences in levels across the groups.
\end{Itemize}

The identification of an appropriate transformation and the understanding of the resultant output is the focus of this section.

\warn{If the assumptions of a one-way ANOVA are not met, then the data may be transformed to a scale where the assumptions are met.}

\subsection{Families of Transformations}
There are two major families of transformations -- power and special transformations. Special transformations are generally identified based on the type of data to be transformed. Certain special transformations are common in particular fields of study and are generally well-known to scientists in those fields. An example that crosses many fields is the transformation of proportions or percentages data by using the arcsine square-root function ($sin^{-1}(\sqrt{Y})$). The effect of this transformation on right-skewed proportions data is illustrated in \figref{fig:OWATransformArcsine}. The histogram for the values on the original scale is shown upside-down in the lower portion of this figure, the transforming function is shown in the middle, and the resultant transformed data is shown sideways on the left. The ``spreading out'' and ``compressing'' can be visualized by drawing a line up from the original scale until the transforming function is met and then moving to the left until the transformed scale is met. This should be tried for a variety of values on the original scale to ``feel'' how the $sin^{-1}(\sqrt{Y})$ transformation spreads out small values and compresses large values.

<<OWATransformArcsine, echo=FALSE, fig.width=6, fig.height=6, fig.cap="Demonstration of the result (left) from applying the arcsine square-root transformation function (blue line) to right-skewed original values (lower).", fig.pos="!h">>=
 par(mar=c(0,0.5,0,1.6), mgp=c(0,0,0),las=1,tcl=-0.2)
 layout(matrix(c(1,3,0,2),nrow=2,byrow=TRUE))
 set.seed(30)
 n <- 100;  p <- 0.05;  succ <- rbinom(500,n,p);  prop <- succ/n
 y4 <- asin(sqrt(prop))
 y.hist <- hist(y4,plot=FALSE,breaks=12)
 barplot(-y.hist$counts,horiz=TRUE,space=c(0,0),col="gray90",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext(expression(asin(sqrt(Y))),side=4,line=0.35)
 par(mar=c(0.5,0,1.5,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 x.hist <- hist(prop,plot=FALSE,breaks=12)
 barplot(-x.hist$counts,space=c(0,0),col="gray90",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext("Y",side=3,line=0)
 par(mar=c(0,0,0,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 curve(asin(sqrt(x)),min(prop),max(prop),n=501,lwd=2,col="blue",xlab="",ylab="",bty="n",xaxt="n",yaxt="n",tck=0)
@

\vspace{12pt}
With power transformations, the response variable is transformed by raising it to a particular power, $\lambda$, i.e., $Y^{\lambda}$ \tabrefp{tab:CommonTranformations}. Each of the power transformations shown in \tabref{tab:CommonTranformations} tends to ``spread out'' relatively small values and ``draw in'' or ``compress'' relatively large values in a distribution. This process is illustrated in \figref{fig:OWATransformLog} for a natural log transformation.\footnote{Try a few values as was done with the $sin^{-1}(\sqrt{Y})$ transformation function in \figref{fig:OWATransformArcsine}.}

\begin{table}[h]
  \centering
  \caption{List of common power transformations in ANOVAs.}\label{tab:CommonTranformations}
  \begin{tabular}{ccccccc}
    \hline\hline
    \widen{-2}{7}{Power} & \multicolumn{2}{c}{Transformation} &  & Power & \multicolumn{2}{c}{Transformation} \\
    \cline{2-3}\cline{6-7}
    \widen{-2}{7}{$\lambda$} & Name & Formula &  & $\lambda$ & Name & Formula \\
    \cline{1-3}\cline{5-7}
    \widen{-2}{7}{1} & Original Scale & $Y^{1}=Y$ &  & 0 & Natural Log & $log(Y)$ \\
    \widen{-2}{7}{0.5} & Square Root & $Y^{0.5}=\sqrt{Y}$ &  & -0.5 & Inverse Root & $Y^{-0.5}=\frac{1}{\sqrt{Y}}$
    \\
    \widen{-2}{7}{0.33} & Cube Root & $Y^{0.33}=\sqrt[3]{Y}$ &  & -1 & Inverse & $Y^{-1}=\frac{1}{Y}$ \\
    \widen{-2}{7}{0.25} & Fourth Root & $Y^{0.25}=\sqrt[4]{Y}$ &  &  &  &  \\
    \hline\hline
  \end{tabular}
\end{table}

<<OWATransformLog, echo=FALSE, fig.width=6, fig.height=6, fig.cap="Demonstration of the result (upper-left) from applying the natural log transformation function (blue line in upper-right) to right-skewed original values (lower-right).", fig.pos="!h">>=
 par(mar=c(0,0.5,0,1.6), mgp=c(0,0,0),las=1,tcl=-0.2)
 layout(matrix(c(1,3,0,2),nrow=2,byrow=TRUE))
 set.seed(10)
 x1 <- rlnorm(500,0,1); y1 <- log(x1)  # lognormal data
 y.hist <- hist(y1,plot=FALSE)
 barplot(-y.hist$counts,horiz=TRUE,space=c(0,0),col="gray90",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext("log(Y)",side=4,line=0)
 par(mar=c(0.5,0,1.5,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 x.hist <- hist(x1,plot=FALSE)
 barplot(-x.hist$counts,space=c(0,0),col="gray90",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext("Y",side=3,line=0)
 par(mar=c(0,0,0,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 curve(log(x),min(x1),max(x1),n=501,lwd=2,col="blue",xlab="",ylab="",bty="n",xaxt="n",yaxt="n",tck=0)
@

<<OWATransformInverse, echo=FALSE, fig.width=6, fig.height=6, fig.cap="Demonstration of the result (upper-left) from applying the inverse transformation function (blue line in upper-right) to right-skewed original values (lower-right).", fig.pos="!h", fig.show='hide'>>=
 par(mar=c(0,0.5,0,1.6), mgp=c(0,0,0),las=1,tcl=-0.2)
 layout(matrix(c(1,3,0,2),nrow=2,byrow=TRUE))
 set.seed(30)
 y3 <- rnorm(500,5,1); x3 <- 1/y3
 y.hist <- hist(y3,plot=FALSE)
 barplot(-y.hist$counts,horiz=TRUE,space=c(0,0),col="white",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext("1/Y",side=4,line=0)
 par(mar=c(0.5,0,1.5,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 x.hist <- hist(x3,plot=FALSE)
 barplot(-x.hist$counts,space=c(0,0),col="white",xaxt="n",yaxt="n",xlab="",ylab="")
 mtext("Y",side=3,line=0)
 par(mar=c(0,0,0,0), mgp=c(0,0,0),las=1,tcl=-0.2)
 curve(1/x,min(x3),max(x3),n=501,lwd=2,col="blue",xlab="",ylab="",bty="n",xaxt="n",yaxt="n",tck=0)
@

\vspace{12pt}
The common transformations listed in \tabref{tab:CommonTranformations} are ordered from least to most powerful moving down the first column and then down the second. In other words, the transformations are listed in order from the transformations that ``spread out'' the small values the least to those that ``spread out'' the small values the most. This ordering can be seen by comparing the transforming functions in \figref{fig:OWATransformFunctions}. Alternatively, the transformations are ordered from those that ``normalize'' mildly skewed data to those that ``normalize'' strongly skewed data.

<<OWATransformFunctions, echo=FALSE, fig.cap="Most common power transformation functions.">>=
 par(mar=c(2,2,0.5,0.5), mgp=c(0.75,0,0),las=1,tcl=-0.2, xaxt="n", yaxt="n")
 mx <- 5
 curve(sqrt(x),0,mx,n=501,lwd=2,xlab="y",ylab="y*",ylim=c(-2,4),col=1)
 curve(x^(1/3),0,mx,n=501,lwd=2,add=TRUE,col=2)
 curve(x^(1/4),0,mx,n=501,lwd=2,add=TRUE,col=3)
 curve(log(x),0,mx,n=501,lwd=2,add=TRUE,col=4)
 curve(1/x,0,mx,n=501,lwd=2,add=TRUE,col=5)
 leg <- c("square root","cube root","fourth root","natural log","inverse")
 legend(0.8,4.1,col=1:5,lwd=2,legend=leg,cex=0.65)
@

\vspace{12pt}
You should also note that it is possible to ``combine'' one of the common powers with the inverse transformation to create a larger array of inverse transformations. For example, a $\lambda$ of -0.5 could be considered an inverse square-root transformation. These types of transformations are common but less common than those listed in \tabref{tab:CommonTranformations}.

\subsubsection{Finding A Power Transformation}
Power transformations require non-negative and non-zero data. Violations of this restriction can be rectified by adding an amount to all values of the response variable such that the all values become positive. In addition, power transformations are not effective if the range of values of the response variable is narrow.\footnote{In effect, the power transformation is basically linear over short ranges and, thus, is not effective.}

%In general, Fox (1997) suggests that if the ratio of the maximum to minimum value of the response variable is less than five, then you should consider subtracting a value just smaller than the minimum value to shift the entire distribution of values closer to zero. These values used to ``shift'' the distribution are commonly called \emph{start} values.

\warn{A positive value should be added to each value of the response variable if a power transformation is to be used and the response variable contains zeroes or negative values.}

%\vspace{-10pt}
%\warn{A negative value may be added to each value of the response variable if a power transformation is to be used and the ratio of maximum to minimum value of the response variable is less than five.}

There are several methods for identifying the power transformation that is most likely to correct problems with assumptions for a one-way ANOVA.\footnote{Box and Cox (1964) provided a statistical and graphical method for identifying the appropriate power transformation for the response variable. The details of this method are beyond the scope of this class but, in general, the method searches for a $\lambda$ that minimizes the RSS (or $SS_{within}$). A slightly modified Box and Cox approach is implemented in R by sending a \R{lm} object to \R{boxcox()} from the \R{MASS} package.} One simple method is trial-and-error -- i.e., trying various powers until one is found where the assumptions of the model are most closely met. This trial-and-error method is tedious but is made more efficient with the use of \R{transChooser()}, the same function used previous when assessing the model assumptions. In addition to the saved \R{lm()} object, a start value can be included with the \R{starty=} argument. As before, a histogram of model residuals, a boxplot of the residuals separated for each group, and p-values for the assumption tests are constructed. A slider is in the ``gear box'' that can be used to ``try'' various values of $\lambda$ with the plots and p-values being updated as $\lambda$ is changed. One can try various values of $\lambda$ until a value is found that provides approximately normal residuals and equal variances. When actually transforming the variable it is best to choose one of the common values of $\lambda$ from \tabref{tab:CommonTranformations} that is closest to the value found by trial-and-error.

Another option for choosing a possible power transformation is to rely on theory related to the response variable. As with the special transformations discussed above, power transformations based on theory will generally be well-known by the scientists within a particular field. However, for example, it is common to transform response variables that are areas by taking the square root and those that are volumes with the cube root. In addition, discrete counts are often transformed with the square root.

\warn{Transformations may be chosen based on known theory regarding the response variable.}

\subsection{Creating Transformed Variables in R}
A power transformation can be carried out by raising the variable to the given power with the \R{\^} symbol. A square-root transformation can also be used by including the variable in \R{sqrt()}. A natural log transformation is accomplished by including the variable in \R{log()}. The arcsine square root transformation requires the combined efforts of \R{asin()} and \R{sqrt()}. The results of the transforming function should be assigned to a new object. The following are examples of creating a transformed variable from a generic variable called $Y$ in a generic data.frame called $df$:

\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm]
df$sqrt.y <- df$Y^(1/2)       # square-root
df$sqrt.y <- sqrt(df$Y)       # also square-root
df$ln.y <- log(df$Y)          # natural log
df$cubert.y <- df$Y^(1/3)     # cube-root
df$inv.y <- df$Y^(-1)         # inverse
df$inv2.y <- 1/df$Y           # also inverse
df$asin.y <- asin(sqrt(df$Y)) # arcsine square-root
\end{Verbatim}


\subsection{Interpretations After Transformations} \label{sect:AOVTransformationsInterp}
Care must be taken with interpretations following transformations. A few simple rules help in this regard:
\begin{Enumerate}
  \item Make sure to tell the reader what transformation you used and how you arrived at it.
  \item Make sure that you refer to the transformed response variable in your conclusions (i.e., say ``the mean square root of the response variable differed among treatment groups'' rather than ``the mean of the response variable'').
  \item The values should be back-transformed to the original scale when referring to means or confidence intervals of means.\footnote{This rule refers more to simple linear regression models where confidence intervals for slopes, which are not means, are of interest.}
\end{Enumerate}

\subsubsection*{Back-Transformation Issues}
Back-transformation is the process of reversing the results found on the transformed scale to the original scale for ease of interpretation. For example, log transformations are reversed with the exponential function and square root transformations are reversed by squaring the results. Wherever possible, back-transformations should be performed in order to provide results on the original scale of measurement. However, back-transformation must be considered carefully because the back-transformed result may be subject to systematic bias.

It is commonly known that back-transforming the mean value on the log scale underestimates the mean value on the original scale. This observation stems from the fact that the back-transformed mean value from the log scale is equal to the geometric mean\footnote{The geometric mean is defined as the $n$th root of the product of the $n$ values.} of the values on the original scale. The geometric mean is always less than the arithmetic mean\footnote{The arithmetic mean is the sum of all values divided by $n$.} and, thus, the back-transformed mean always underestimates the arithmetic mean from the original scale. A wide variety of ``corrections'' for this back-transformation bias with logarithms have been suggested in the literature. The most common correction, derived from the analysis of normal and log-normal distributional theory, is to multiply the back-transformed value by
\[ e^{\frac{MS_{Within}}{2}} \]

Another issue arises when back-transforming differences in means. For example, because the difference in the log of two values is equal to the log of the ratio of the two values, the back-transformed difference in two values becomes the ratio of the two values; i.e.,

\[ e^{log(x_{1})-log(x_{2})} = e^{log(\frac{x_{1}}{x_{2}})} = \frac{x_{1}}{x_{2}} \]

Thus, a confidence interval for the difference in two means of a log-transformed variable becomes a confidence interval for the RATIO of two means on the original scale.

\section{Example Analyses III}
\vspace{-12pt}
\subsection{Peak Discharge}
\vspace{-12pt}
<<echo=FALSE>>=
PD <- read.csv("data/PeakDischarge.csv")
PD$method <- factor(PD$method)
pd.lm <- lm(discharge~method,data=PD)
pd.lev <- levenesTest(pd.lm)
pd.ad <- adTest(pd.lm$residuals)
pd.out <- outlierTest(pd.lm)
PD$sqrtdis <- sqrt(PD$discharge)
pd.lm1 <- lm(sqrtdis~method,data=PD)
pd.lev1 <- levenesTest(pd.lm1)
pd.ad1 <- adTest(pd.lm1$residuals)
pd.out1 <- outlierTest(pd.lm1)
@
Mathematical models are used to predict flood flow frequency and estimates of peak discharge for the Mississippi River watershed. These models are important for forecasting potential dangers to the public. A civil engineer is interested in determining whether four different methods for estimating flood flow frequency produce equivalent estimates of peak discharge when applied to the same watershed. The statistical hypotheses to be examined are
\[ \begin{split}
   H_{0}&: \mu_{1} = \mu_{2} = \mu_{3} = \mu_{4} \\
   H_{A}&:\text{At least one pair of means is different}
\end{split} \]

where the subscripts identify the four different methods.

\subsubsection*{Data Collection}
\vspace{-12pt}
Each estimation method was used six times on the watershed and the resulting discharge estimates (in cubic feet per second) were recorded.

\subsubsection*{EDA \& Assumption Checking}
\vspace{-12pt}
From the information given, the data do not appear to be independent either within treatments or among treatments (i.e., they are all on the same watershed). This assumption appears to be violated. However, the single watershed is the ``population'' of interest to the engineer. Thus, this form of data collection is not problematic unless the engineer (or you) attempt to make strict inferences to other watersheds. The variances among treatments appear to be non-constant (Levene's \Sexpr{kPvalue(pd.lev[1,"Pr(>F)"],digits=3)}). The residual plot from the initial ANOVA fit also indicates a heteroscedasticity \figrefp{fig:OWAEx3ResidPlot1}. Even thought the residuals appear normal (Anderson-Darling \Sexpr{kPvalue(pd.ad$p.value,digits=3)}) and there are no significant outliers (outlier test \Sexpr{kPvalue(pd.out$bonf.p,digits=3)}), the unequal variances suggests the need for a transformation.

\begin{figure}[h]
  \centering
  \includegraphics[width=5in]{FigsStatic/OWAEx3ResidPlot1.jpg}
  \caption{Residual plot (Left) and histogram of residuals (Right) from the one-way ANOVA on raw peak discharge data.}\label{fig:OWAEx3ResidPlot1}
\end{figure}

\vspace{9pt}
It was determined, through \R{transChooser()}, that the square root transformation resulted in equal variances (Levene's \Sexpr{kPvalue(pd.lev1[1,"Pr(>F)"],digits=3)}; \figref{fig:OWAEx3ResidPlot2}), normal residuals (Anderson Darling \Sexpr{kPvalue(pd.ad1$p.value,digits=3)}), and no significant outliers (outlier test \Sexpr{kPvalue(pd.out1$bonf.p,digits=3)}). Thus, the assumptions of the ANOVA model appeared to have been adequately met on the square-root scale.

\begin{figure}[h]
  \centering
  \includegraphics[width=5in]{FigsStatic/OWAEx3ResidPlot2.jpg}
  \caption{Residual plot (Left) and histogram of residuals (Right) from one-way ANOVA on square root transformed peak discharge data.}\label{fig:OWAEx3ResidPlot2}
\end{figure}

\subsubsection*{Results}
\vspace{-12pt}
There appeared to be a significant difference in mean square root peak discharge among the four methods (\Sexpr{kPvalue(anova(pd.lm1)[1,"Pr(>F)"],digits=3)}; \tabref{tab:OWAEx3Results1}). Tukey's HSD multiple comparison method indicated that no two means were equal \tabrefp{tab:OWAEx3Results2} and, thus, the mean square-root of peak discharge increased significantly at each step from method 1 to  method 4 \figrefp{fig:OWAEx3Means1}.

\begin{table}[h]
  \centering
  \caption{ANOVA results of square-root peak discharge for four methods.}\label{tab:OWAEx3Results1}
\vspace{-12pt}
<<echo=FALSE, background='white'>>=
kANOVA(pd.lm1)
@
\end{table}

\begin{table}[h]
  \centering
  \caption{Tukey adjusted p-values for pairwise comparisons of square-root peak discharge for four methods.}\label{tab:OWAEx3Results2}
\vspace{-12pt}
<<echo=FALSE, background='white'>>=
pd.mc <- glht(pd.lm1, mcp(method = "Tukey"))
kGLHT(pd.mc)
@
\end{table}

<<OWAEx3Means1, echo=FALSE, fig.cap="Plot of the mean square root transformed peak discharge data with 95\\% confidence intervals and significance notations.">>=
fitPlot(pd.lm1,xlab="Method",ylab="sqrt(Peak Discharge)")
addSigLetters(pd.lm1,c("a","b","c","d"),pos=c(2,4,2,4))
@

\subsubsection*{Conclusion}
\vspace{-12pt}
The four methods produced significantly different mean square-root peak discharge estimates. The methods when ranked from lowest to highest estimates are as follows: method 1, method 2, method 3, and method 4. Broader inferences cannot be made because there appears to be no randomization in this experimental design (at least from the information that is given).

\subsubsection*{Appendix -- R commands}
\vspace{-12pt}
\begin{Verbatim}[formatcom=\color{red},xleftmargin=5mm,commandchars=\\\{\}]
PeakDischarge <- read.csv("PeakDischarge.csv")
PeakDischarge$method <- factor(PeakDischarge$method)
pd.lm <- lm(discharge~method,data=PeakDischarge)
transChooser(pd.lm)
PeakDischarge$sqrtdis <- sqrt(PeakDischarge$discharge)
pd.lm1 <- lm(sqrtdis~method,data=PeakDischarge)
transChooser(pd.lm1)
anova(pd.lm1)
pd.mc1 <- glht(pd.lm1,mcp(method="Tukey"))
summary(pd.mc1)
fitPlot(pd.lm1,xlab="Method",ylab="sqrt(Peak Discharge)")
addSigLetters(pd.lm1,c("a","b","c","d"),pos=c(2,4,2,4))
\end{Verbatim}


\section{Summary Process}
The process of fitting and interpreting linear models is as much an art as it is a science. The ``feel'' for fitting these models comes with experience. The following is a process to consider for fitting a one-way ANOVA model. Consider this process as you learn to fit one-way ANOVA models, but don't consider this to be a concrete process for all models.

\begin{Enumerate}
  \item Perform a thorough EDA of the quantitative response variable.
    \begin{Itemize}
      \item Pay close attention to the distributional shape, center, dispersion, and outliers within each level of the factor variable.
    \end{Itemize}
  \item Fit the untransformed ultimate full model [\R{lm()}].
  \item Check the assumptions of the fit of the untransformed model with \R{transChooser()}.
    \begin{Itemize}
      \item Check equality of variances with a Levene's test and residual plot.
      \item Check normality of residuals with an Anderson-Darling test and histogram of residuals.
      \item Check for outliers with an outlier test, residual plot, and histogram of residuals.
    \end{Itemize}
  \item If an assumption or assumptions are violated, then attempt to find a transformation where the assumptions are met.
    \begin{Itemize}
      \item Use the trial-and-error method [\R{transChooser()}], theory, or experience to identify a possible transformation.
      \item If only an outlier exists (i.e., equal variances and normal residuals) and no transformation corrects the ``problem'' then consider removing the outlier from the data set.
      \item Fit the ultimate full model with the transformed response or reduced data set.
    \end{Itemize}
  \item Construct an ANOVA table for the full model [\R{anova()}] and interpret the overall F-test.
  \item If differences among level means exist, then use a multiple comparison technique [\R{glht()}] to identify specific differences.
    \begin{Itemize}
      \item Use Tukey's HSD method if comparing all possible pairs of means.
      \item Use Dunnett's method if comparing all group means to one specific group mean (e.g., a control).
    \end{Itemize}
  \item Summarize findings with significance letters [\R{addSigLetters()}] on a means plot [\R{fitPlot()}] or table [\R{Summarize()}].
\end{Enumerate}
